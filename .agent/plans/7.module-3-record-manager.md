# Module 3: Record Manager

✅ **Simple** - Single-pass executable, low risk

## Overview

Add document-level content deduplication using SHA-256 hashing. When a user uploads a file, compute its hash and compare against existing documents to detect duplicates and changes.

## Behavior

| Scenario | Action |
|----------|--------|
| Exact duplicate (same hash, active document exists) | Reject with 409 Conflict |
| Updated file (same filename, different hash) | Auto-delete old document + chunks, process new version |
| Previous upload failed (same hash, only failed records) | Allow re-upload |
| New file (no hash match) | Process normally |

## Changes

### 1. Database Migration
- `supabase/migrations/20260216000000_module3_record_manager.sql`
- Add `content_hash TEXT` column to documents (nullable)
- Add index on `(user_id, content_hash)`

### 2. Backend Upload Endpoint
- `backend/app/routers/documents.py`
- Compute SHA-256 hash after reading file bytes
- Check for duplicate hash → 409 Conflict
- Auto-replace same-filename documents with different content
- Include content_hash in document record insert

### 3. Schema Updates
- `backend/app/models/schemas.py` - Add `content_hash` to DocumentResponse
- `frontend/src/types/index.ts` - Add `content_hash` to Document interface

### 4. Frontend UX
- `frontend/src/components/documents/DocumentUpload.tsx` - Yellow warning styling for duplicate errors

### 5. Validation
- API-41 to API-44: Hash in response, duplicate 409, re-upload after delete, auto-replace
- E2E-28: Duplicate upload shows yellow warning in UI

## Verification
1. Apply migration: `supabase db push`
2. Restart backend
3. Upload file → verify content_hash in response
4. Upload same file → verify 409
5. Upload same filename with different content → verify old replaced
